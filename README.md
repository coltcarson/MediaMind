# ðŸŽ¥ MediaMind

MediaMind is an AI-powered tool that transcribes and summarizes .mov video files using OpenAI's Whisper model for transcription and GPT-4o for summarization.

## âœ¨ Features

- ðŸŽ¬ Specialized .mov video file processing
- ðŸ”Š Audio extraction from video files
- ðŸŽ¯ Transcription using OpenAI's Whisper
- ðŸ¤– Intelligent summarization using GPT-4o
- ðŸ“ Markdown output for transcriptions and summaries
- ðŸ’» Command-line interface for batch processing
- ðŸ“Š Progress tracking for long-running tasks
- ðŸ”’ Secure API key handling

## ðŸš€ Installation

1. ðŸ“¥ Clone the repository:
   ```bash
   git clone https://github.com/yourusername/mediamind.git
   cd mediamind
   ```

2. ðŸ Set up Python virtual environment (requires Python 3.11):
   ```bash
   # Create virtual environment
   python3.11 -m venv venv

   # Activate virtual environment (macOS/Linux)
   source venv/bin/activate

   # Activate virtual environment (Windows)
   .\venv\Scripts\activate
   ```

3. ðŸŽµ Install FFmpeg (required for media processing):
   ```bash
   # macOS (using Homebrew)
   brew install ffmpeg

   # Ubuntu/Debian
   sudo apt-get install ffmpeg

   # Windows (using Chocolatey)
   choco install ffmpeg
   ```

4. ðŸ“¦ Install the package and dependencies:
   ```bash
   # Install in development mode
   pip install -e .

   # Install dependencies
   pip install -r requirements.txt

   # Optional: Install development dependencies
   pip install -r requirements-dev.txt
   ```

## âš™ï¸ Configuration

1. ðŸ“„ Copy `.env.example` to `.env`
   ```bash
   cp .env.example .env
   ```

2. ðŸ”‘ Add your OpenAI API key to `.env`:
   ```
   OPENAI_API_KEY=your-api-key-here
   ```

## ðŸ“š Usage

Make sure your virtual environment is activated:
```bash
source venv/bin/activate  # macOS/Linux
.\venv\Scripts\activate   # Windows
```

### Process a single .mov file:
```bash
python -m mediamind process "path/to/your/video.mov"
```

### Batch process multiple .mov files in a directory:
```bash
python -m mediamind batch "path/to/directory"
```

### Generate summary from an existing transcript:
```bash
python -m mediamind summarize "path/to/transcript.md"
```

### Output
Transcripts and summaries are saved in the `transcripts` directory with timestamps:
```
transcripts/
â”œâ”€â”€ video_20250112_103121.md
â””â”€â”€ video_summary_20250112_103121.md
```

## ðŸ—ï¸ Project Structure

```
mediamind/
â”œâ”€â”€ src/mediamind/         # Source code
â”‚   â”œâ”€â”€ __init__.py       # Package initialization
â”‚   â”œâ”€â”€ __main__.py       # CLI entry point
â”‚   â”œâ”€â”€ audio_processor.py # Audio processing module
â”‚   â”œâ”€â”€ summarizer.py     # Text summarization module
â”‚   â””â”€â”€ transcriber.py    # Audio transcription module
â”œâ”€â”€ tests/                # Test files
â”‚   â”œâ”€â”€ conftest.py      # Shared test fixtures
â”‚   â”œâ”€â”€ test_audio_processor.py
â”‚   â”œâ”€â”€ test_summarizer.py
â”‚   â””â”€â”€ test_transcriber.py
â”œâ”€â”€ .env.example         # Example environment variables
â”œâ”€â”€ .pre-commit-config.yaml
â”œâ”€â”€ LICENSE
â”œâ”€â”€ README.md
â”œâ”€â”€ requirements.txt     # Production dependencies
â””â”€â”€ requirements-dev.txt # Development dependencies
```

## ðŸ“ Example Outputs

### ðŸ“œ Transcription Output
```markdown
# Video: interview.mov
## Timestamp: 00:00:00 - 00:00:30
Speaker 1: Welcome to our tech talk. Today we're discussing AI and its impact...

## Timestamp: 00:00:30 - 00:01:00
Speaker 2: Thank you for having me. I believe AI will revolutionize...
```

### ðŸ“‹ Summary Output
```markdown
# Summary: interview.mov

## Key Points
- Discussion focused on AI's impact on technology
- Speakers explored future applications
- Highlighted ethical considerations

## Main Topics
1. Current state of AI technology
2. Future developments
3. Ethical implications

## Action Items
- Research specific use cases
- Follow up on regulatory frameworks
- Schedule follow-up discussion
```

## ðŸ”§ API Documentation

### ðŸŽµ AudioProcessor
```python
def process_file(file_path: str) -> str:
    """Process audio/video file and extract audio.

    Args:
        file_path: Path to the input media file

    Returns:
        Path to the extracted audio file

    Raises:
        UnsupportedFormatError: If file format is not supported
        FileNotFoundError: If input file doesn't exist
    """
```

### ðŸŽ¤ Transcriber
```python
def transcribe(audio_path: str) -> str:
    """Transcribe audio file using OpenAI Whisper.

    Args:
        audio_path: Path to the audio file

    Returns:
        Markdown formatted transcription
    """
```

### ðŸ“ Summarizer
```python
def summarize(transcript: str) -> str:
    """Generate summary from transcript using GPT-4o.

    Args:
        transcript: Markdown formatted transcript

    Returns:
        Markdown formatted summary
    """
```

## âš ï¸ Error Handling

The application handles the following errors:
- `UnsupportedFormatError`: Raised when input file format is not supported
- `FileNotFoundError`: Raised when input file doesn't exist
- `APIError`: Raised when there are issues with OpenAI API calls
- `TranscriptionError`: Raised when transcription fails
- `SummarizationError`: Raised when summary generation fails

## ðŸ‘©â€ðŸ’» Development

1. ðŸ“¦ Set up the development environment:
   ```bash
   # Install all dependencies and set up pre-commit hooks
   make install
   ```

2. ðŸ§ª Run tests:
   ```bash
   # Run all tests with coverage report
   make test
   ```

3. ðŸ” Run linting and type checking:
   ```bash
   # Run all pre-commit hooks
   make lint
   ```

4. ðŸ§¹ Clean up generated files:
   ```bash
   make clean
   ```

5. ðŸ“ Update dependencies:
   ```bash
   # Update requirements.txt and requirements-dev.txt
   make update-deps
   ```

## ðŸ¤ Contributing

Please read our [Contributing Guidelines](CONTRIBUTING.md) for details on our code of conduct and the process for submitting pull requests.

## ðŸ”„ Continuous Integration

We use GitHub Actions for continuous integration. Every pull request will automatically:
- Run all tests
- Check code formatting (black)
- Run linting (flake8)
- Check import sorting (isort)
- Perform type checking (mypy)
- Generate test coverage report

## ðŸ“„ License

MIT License - see [LICENSE](LICENSE) file for details.

## ðŸ™ Acknowledgments

- OpenAI for the Whisper and GPT-4o models
- FFmpeg for media processing capabilities
- All our contributors and users
>>>>>>> development
